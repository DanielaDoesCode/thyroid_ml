{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# from ydata_profiling import ProfileReport\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import f1_score #, confusion_matrix\n",
    "from sklearn.metrics import r2_score #, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, matthews_corrcoef\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "import scipy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_target(diagnoses):\n",
    "    if diagnoses == '-':\n",
    "        return 'healthy'\n",
    "    elif diagnoses in 'ABCD':\n",
    "        return 'hyperthyroid condition'\n",
    "    elif diagnoses in 'EFGH':\n",
    "        return 'hypothyroid condition'\n",
    "    elif diagnoses in 'IJ':\n",
    "        return 'binding protein'\n",
    "    elif diagnoses in 'K':\n",
    "        return 'general health'\n",
    "    elif diagnoses in 'LMN':\n",
    "        return 'replacement therapy'\n",
    "    elif diagnoses == 'R':\n",
    "        return 'discordant results'\n",
    "    else:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data = pd.read_csv(\"../proj-data-c.csv\")\n",
    "data = data.drop(columns=['referral source:'])\n",
    "data = data.drop(columns=['[record identification]'])\n",
    "data = data[data['sex:'] != '?']\n",
    "columns_with_question_mark = data.columns[data.apply(lambda col: (col == '?').any())]\n",
    "for column in columns_with_question_mark:\n",
    "    data[column] = data[column].replace('?', np.nan)\n",
    "data['target'] = data['diagnoses'].apply(convert_to_target)\n",
    "data = data[data['age:'] <= 100]\n",
    "y = data['target']\n",
    "X = data.drop(columns=['diagnoses'])\n",
    "X = X.drop(columns=['target'])\n",
    "np.random.seed(0)\n",
    "major_class = y.value_counts().idxmax()\n",
    "major_class_indices = y[y == major_class].index\n",
    "drop_indices = np.random.choice(major_class_indices, size=int(len(major_class_indices)/2), replace=False)\n",
    "X = X.drop(drop_indices)\n",
    "y = y.drop(drop_indices)\n",
    "X = X.replace('f', 0)\n",
    "X = X.replace('t', 1)\n",
    "X = X.replace('M', 0)\n",
    "X = X.replace('F', 1)\n",
    "\n",
    "X = X.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "models = {'LogisticRegression': LogisticRegression(),'XGBoost': XGBClassifier(),'RandomForest': RandomForestClassifier(n_estimators=100),\n",
    "    'DecisionTree': DecisionTreeClassifier(),'SVM': SVC(),'KNN': KNeighborsClassifier(n_neighbors=10, weights='distance')}\n",
    "selected_features = {}\n",
    "for name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    sfs = SequentialFeatureSelector(model, n_features_to_select=8, n_jobs=-1)\n",
    "    sfs.fit(X, y)\n",
    "    mask = sfs.get_support()\n",
    "    selected_features[name] = X.columns[mask]\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    #print(f'Features for {name}: {selected_features[name]}')\n",
    "    #print(f'Time taken for {name}: {elapsed_time} seconds\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of the f1 score LogisticRegression with SimpleImputer and StandardScaler: 0.5451400373038456\n",
      "Average of the f1 score LogisticRegression with SimpleImputer and MinMaxScaler: 0.23449081889254786\n",
      "Average of the f1 score LogisticRegression with KNNImputer and StandardScaler: 0.5451400373038456\n",
      "Average of the f1 score LogisticRegression with KNNImputer and MinMaxScaler: 0.23449081889254786\n",
      "Average of the f1 score XGBoost with SimpleImputer and StandardScaler: 0.8468581602743479\n",
      "Average of the f1 score XGBoost with SimpleImputer and MinMaxScaler: 0.8468581602743479\n",
      "Average of the f1 score XGBoost with KNNImputer and StandardScaler: 0.8468581602743479\n",
      "Average of the f1 score XGBoost with KNNImputer and MinMaxScaler: 0.8468581602743479\n",
      "Average of the f1 score RandomForest with SimpleImputer and StandardScaler: 0.8828193626380185\n",
      "Average of the f1 score RandomForest with SimpleImputer and MinMaxScaler: 0.8661704783009991\n",
      "Average of the f1 score RandomForest with KNNImputer and StandardScaler: 0.8881340947050402\n",
      "Average of the f1 score RandomForest with KNNImputer and MinMaxScaler: 0.886039865692439\n",
      "Average of the f1 score DecisionTree with SimpleImputer and StandardScaler: 0.8063115502079329\n",
      "Average of the f1 score DecisionTree with SimpleImputer and MinMaxScaler: 0.8105079522790737\n",
      "Average of the f1 score DecisionTree with KNNImputer and StandardScaler: 0.8211408590744558\n",
      "Average of the f1 score DecisionTree with KNNImputer and MinMaxScaler: 0.8224820394194536\n",
      "Average of the f1 score SVM with SimpleImputer and StandardScaler: 0.35842850268286525\n",
      "Average of the f1 score SVM with SimpleImputer and MinMaxScaler: 0.2088373834490914\n",
      "Average of the f1 score SVM with KNNImputer and StandardScaler: 0.35842850268286525\n",
      "Average of the f1 score SVM with KNNImputer and MinMaxScaler: 0.2088373834490914\n",
      "Average of the f1 score KNN with SimpleImputer and StandardScaler: 0.5889637003473016\n",
      "Average of the f1 score KNN with SimpleImputer and MinMaxScaler: 0.576960388956213\n",
      "Average of the f1 score KNN with KNNImputer and StandardScaler: 0.5889637003473016\n",
      "Average of the f1 score KNN with KNNImputer and MinMaxScaler: 0.576960388956213\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "selected_features={'LogisticRegression': ['on thyroxine:', 'query hyperthyroid:', 'TSH:', 'T3 measured:', 'T3:','T4U measured:', 'T4U:', 'TBG:'],\n",
    "                   'XGBoost':['on thyroxine:', 'thyroid surgery:', 'TSH:', 'T3:', 'TT4:', 'T4U:','FTI:', 'TBG:'],\n",
    "                   'RandomForest': ['on thyroxine:', 'pregnant:', 'TSH:', 'T3:', 'TT4:', 'T4U:', 'FTI:','TBG:'],\n",
    "                   'DecisionTree':['sex:', 'on thyroxine:', 'thyroid surgery:', 'TSH:', 'T3:', 'T4U:','FTI:', 'TBG:'],\n",
    "                   'SVM': ['sex:', 'on thyroxine:', 'query on thyroxine:','on antithyroid medication:', 'sick:', 'TSH:', 'T3:', 'TBG:'],\n",
    "                   'KNN': ['on thyroxine:', 'on antithyroid medication:', 'pregnant:', 'tumor:','TSH:', 'T3:', 'T4U:', 'TBG:']}\n",
    "models = {'LogisticRegression': LogisticRegression(),'XGBoost': XGBClassifier(),'RandomForest': RandomForestClassifier(n_estimators=100),\n",
    "    'DecisionTree': DecisionTreeClassifier(),'SVM': SVC(),'KNN': KNeighborsClassifier(n_neighbors=10, weights='distance'),}\n",
    "imputers = [('SimpleImputer', SimpleImputer(strategy='mean')), ('KNNImputer', KNNImputer(n_neighbors=2, weights=\"uniform\"))]\n",
    "scalers = [('StandardScaler', StandardScaler()), ('MinMaxScaler', MinMaxScaler())]\n",
    "for model_name, model in models.items():\n",
    "    best_features = selected_features[model_name]\n",
    "    X_best = X[best_features]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_best, y, test_size=0.2, random_state=42)\n",
    "    for imputer_name, imputer in imputers:\n",
    "        X_train_imputed = imputer.fit_transform(X_train)\n",
    "        X_test_imputed = imputer.transform(X_test)\n",
    "        for scaler_name, scaler in scalers:\n",
    "            X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "            X_test_scaled = scaler.transform(X_test_imputed)\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            print(f'Average of the f1 score {model_name} with {imputer_name} and {scaler_name}: {f1_score(y_test, y_pred, average='macro')}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'xgb__colsample_bytree': 0.7, 'xgb__gamma': 0, 'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__min_child_weight': 1, 'xgb__subsample': 0.7}\n",
      "Best score:  0.8639739655822434\n",
      "Best parameters:  {'rf__max_depth': None, 'rf__n_estimators': 500}\n",
      "Best score:  0.8729507501945012\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "steps_xgb = [('imputer', SimpleImputer()),('scaler', StandardScaler()),('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))]\n",
    "pipeline_xgb = Pipeline(steps_xgb)\n",
    "param_grid_xgb = {'xgb__learning_rate': [0.01, 0.1],'xgb__max_depth': [3, 4, 5],'xgb__min_child_weight': [1, 2],'xgb__gamma': [0, 0.1, 0.2],\n",
    "    'xgb__subsample': [0.6, 0.7],'xgb__colsample_bytree': [0.6, 0.7]}\n",
    "grid_search_xgb = GridSearchCV(pipeline_xgb, param_grid_xgb, cv=5, scoring='f1_macro')\n",
    "X_xgb = X[selected_features['XGBoost']]\n",
    "grid_search_xgb.fit(X_xgb, y)\n",
    "xbg_best_params = grid_search_xgb.best_params_\n",
    "print(\"Best parameters: \", grid_search_xgb.best_params_)\n",
    "print(\"Best score: \", grid_search_xgb.best_score_)\n",
    "steps_rf = [('imputer', SimpleImputer()),('scaler', StandardScaler()),('rf', RandomForestClassifier())]\n",
    "pipeline_rf = Pipeline(steps_rf)\n",
    "param_grid_rf = {'rf__n_estimators': [100, 200, 500, 1000],'rf__max_depth': [None, 5, 10, 15]}\n",
    "grid_search_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=5, scoring='f1_macro')\n",
    "grid_search_rf.fit(X, y)\n",
    "rf_best_params = grid_search_rf.best_params_ \n",
    "print(\"Best parameters: \", grid_search_rf.best_params_)\n",
    "print(\"Best score: \", grid_search_rf.best_score_)\n",
    "steps_dt = [('imputer', SimpleImputer()),('scaler', StandardScaler()),('dt', DecisionTreeClassifier())]\n",
    "pipeline_dt = Pipeline(steps_dt)\n",
    "param_grid_dt = {'dt__criterion': ['gini', 'entropy'],'dt__max_depth': [None, 5, 10, 15],'dt__min_samples_split': [2, 5, 10],'dt__min_samples_leaf': [1, 2, 5, 10],\n",
    "    'dt__max_features': ['auto', 'sqrt', 'log2', None]}\n",
    "grid_search_dt = GridSearchCV(pipeline_dt, param_grid_dt, cv=5, scoring='f1_macro')\n",
    "X_dt = X[selected_features['DecisionTree']]\n",
    "grid_search_dt.fit(X_dt, y)\n",
    "dt_best_params = grid_search_dt.best_params_\n",
    "#print(\"Best parameters: \", grid_search_dt.best_params_)\n",
    "#print(\"Best score: \", grid_search_dt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"../proj-data-c.csv\")\n",
    "data = data.drop(columns=['referral source:'])\n",
    "data = data.drop(columns=['[record identification]'])\n",
    "missing_sex_percentage = (data['sex:'] == '?').mean() * 100\n",
    "data = data[data['sex:'] != '?']\n",
    "columns_with_question_mark = data.columns[data.apply(lambda col: (col == '?').any())]\n",
    "for column in columns_with_question_mark:\n",
    "    data[column] = data[column].replace('?', np.nan)\n",
    "data = data.fillna(-1)\n",
    "data = data[data['age:'] <= 100]\n",
    "y = data['age:']\n",
    "data['diagnoses'] = data['diagnoses'].apply(convert_to_target)\n",
    "data = data.replace('f', 0)\n",
    "data = data.replace('t', 1)\n",
    "data = data.replace('M', 0)\n",
    "data = data.replace('F', 1)\n",
    "data = data.replace('healthy', 0)\n",
    "data = data.replace('hyperthyroid condition', 1)\n",
    "data = data.replace('hypothyroid condition', 2)\n",
    "data = data.replace('binding protein', 3)\n",
    "data = data.replace('general health', 4)\n",
    "data = data.replace('replacement therapy', 5)\n",
    "data = data.replace('discordant results', 6)\n",
    "data = data.replace('other', 7)\n",
    "X = data.drop(columns=['age:'])\n",
    "X = X.replace('f', 0)\n",
    "X = X.replace('t', 1)\n",
    "X = X.replace('M', 0)\n",
    "X = X.replace('F', 1)\n",
    "X = X.replace('healthy', 0)\n",
    "X = X.replace('hyperthyroid condition', 1)\n",
    "X = X.replace('hypothyroid condition', 2)\n",
    "X = X.replace('binding protein', 3)\n",
    "X = X.replace('general health', 4)\n",
    "X = X.replace('replacement therapy', 5)\n",
    "X = X.replace('discordant results', 6)\n",
    "X = X.replace('other', 7)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for LinearRegression: Index(['sick:', 'pregnant:', 'psych:', 'TSH measured:', 'T3 measured:', 'T3:',\n",
      "       'TT4:', 'FTI:'],\n",
      "      dtype='object')\n",
      "Time taken for LinearRegression: 5.473840951919556 seconds\n",
      "\n",
      "Features for Ridge: Index(['sick:', 'pregnant:', 'psych:', 'TSH measured:', 'T3 measured:', 'T3:',\n",
      "       'TT4:', 'FTI:'],\n",
      "      dtype='object')\n",
      "Time taken for Ridge: 2.5327494144439697 seconds\n",
      "\n",
      "Features for Lasso: Index(['sex:', 'TSH:', 'T3:', 'TT4 measured:', 'TT4:', 'FTI:', 'TBG:',\n",
      "       'diagnoses'],\n",
      "      dtype='object')\n",
      "Time taken for Lasso: 2.5410025119781494 seconds\n",
      "\n",
      "Features for DecisionTreeRegressor: Index(['sick:', 'pregnant:', 'I131 treatment:', 'hypopituitary:', 'psych:',\n",
      "       'TSH measured:', 'T3 measured:', 'T3:'],\n",
      "      dtype='object')\n",
      "Time taken for DecisionTreeRegressor: 2.878739356994629 seconds\n",
      "\n",
      "Features for KNN: Index(['on antithyroid medication:', 'pregnant:', 'lithium:', 'hypopituitary:',\n",
      "       'psych:', 'TSH measured:', 'T3:', 'FTI measured:'],\n",
      "      dtype='object')\n",
      "Time taken for KNN: 7.3564348220825195 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "models = {'LinearRegression': LinearRegression(),'Ridge': Ridge(),'Lasso': Lasso(alpha=1.0),'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
    "    'KNN': KNeighborsRegressor(n_neighbors=10, weights='distance')}\n",
    "selected_features = {}\n",
    "for name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    sfs = SequentialFeatureSelector(model, n_features_to_select=8, n_jobs=-1)\n",
    "    sfs.fit(X, y)\n",
    "    mask = sfs.get_support()\n",
    "    selected_features[name] = X.columns[mask]\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'Features for {name}: {selected_features[name]}')\n",
    "    print(f'Time taken for {name}: {elapsed_time} seconds\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of LinearRegression with KNNImputer and StandardScaler: 348.90916497995005\n",
      "MSE of LinearRegression with KNNImputer and MinMaxScaler: 348.90916497995005\n",
      "MSE of Ridge with KNNImputer and StandardScaler: 343.851092549785\n",
      "MSE of Ridge with KNNImputer and MinMaxScaler: 343.83885754805226\n",
      "MSE of Lasso with KNNImputer and StandardScaler: 349.87467322801245\n",
      "MSE of Lasso with KNNImputer and MinMaxScaler: 351.75550866644494\n",
      "MSE of DecisionTreeRegressor with KNNImputer and StandardScaler: 340.22395472836905\n",
      "MSE of DecisionTreeRegressor with KNNImputer and MinMaxScaler: 340.6841237424536\n",
      "MSE of KNN with KNNImputer and StandardScaler: 921.7225352112677\n",
      "MSE of KNN with KNNImputer and MinMaxScaler: 954.1197183098592\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "selected_features = {'LinearRegression': ['query hyperthyroid:', 'lithium:', 'goitre:', 'tumor:','hypopituitary:', 'psych:', 'TSH:', 'T4U:'],\n",
    "    'Ridge': ['on antithyroid medication:', 'pregnant:', 'thyroid surgery:','I131 treatment:', 'query hyperthyroid:', 'tumor:', 'TSH:','T4U measured:'],\n",
    "    'Lasso': ['sex:', 'on thyroxine:', 'query on thyroxine:','on antithyroid medication:', 'sick:', 'TSH:', 'TT4:', 'FTI:'],\n",
    "    'DecisionTreeRegressor': ['sex:', 'on thyroxine:', 'query on thyroxine:','on antithyroid medication:', 'sick:', 'pregnant:', 'TSH measured:','T3:'],\n",
    "    'KNN': ['sex:', 'on thyroxine:', 'query on thyroxine:','on antithyroid medication:', 'sick:', 'pregnant:', 'T3 measured:','T3:'],}\n",
    "models = {'LinearRegression': LinearRegression(),'Ridge': Ridge(),'Lasso': Lasso(alpha=1.0),'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=10, weights='distance')}\n",
    "imputers = [('SimpleImputer', SimpleImputer(strategy='mean')), ('KNNImputer', KNNImputer(n_neighbors=2, weights=\"uniform\"))]\n",
    "scalers = [('StandardScaler', StandardScaler()), ('MinMaxScaler', MinMaxScaler())]\n",
    "for model_name, model in models.items():\n",
    "    best_features = selected_features[model_name]\n",
    "    X_best = X[best_features]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_best, y, test_size=0.2, random_state=42)\n",
    "    for imputer_name, imputer in imputers:\n",
    "        X_train_imputed = imputer.fit_transform(X_train)\n",
    "        X_test_imputed = imputer.transform(X_test)\n",
    "    for scaler_name, scaler in scalers:\n",
    "        X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "        X_test_scaled = scaler.transform(X_test_imputed)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        print(f'MSE of {model_name} with {imputer_name} and {scaler_name}: {mean_squared_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'Ridge__alpha': 10.0, 'Ridge__fit_intercept': True, 'Ridge__solver': 'sag'}\n",
      "Best score:  -346.864224452166\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "steps_ridge = [('imputer', KNNImputer()),('scaler', StandardScaler()),('Ridge', Ridge())]\n",
    "pipeline_ridge = Pipeline(steps_ridge)\n",
    "param_grid_ridge = {\n",
    "    'Ridge__alpha': [0.1, 1.0, 10.0],\n",
    "    'Ridge__fit_intercept': [True, False],\n",
    "    'Ridge__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "}\n",
    "grid_search_ridge = GridSearchCV(pipeline_ridge, param_grid_ridge, cv=5, scoring='neg_mean_squared_error')\n",
    "X_ridge = X[selected_features['Ridge']]\n",
    "grid_search_ridge.fit(X_ridge, y)\n",
    "ridge_best_params = grid_search_ridge.best_params_\n",
    "print(\"Best parameters: \", grid_search_ridge.best_params_)\n",
    "print(\"Best score: \", grid_search_ridge.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../proj-data-c.csv\")\n",
    "data = data.drop(columns=['referral source:'])\n",
    "data = data.drop(columns=['[record identification]'])\n",
    "missing_sex_percentage = (data['sex:'] == '?').mean() * 100\n",
    "data = data[data['sex:'] != '?']\n",
    "columns_with_question_mark = data.columns[data.apply(lambda col: (col == '?').any())]\n",
    "for column in columns_with_question_mark:\n",
    "    data[column] = data[column].replace('?', np.nan)\n",
    "y = data['sex:']\n",
    "X = data.drop(columns=['sex:'])\n",
    "X = X.replace('f', 0)\n",
    "X = X.replace('t', 1)\n",
    "X = X.fillna(-1)\n",
    "le = LabelEncoder()\n",
    "X['diagnoses'] = le.fit_transform(X['diagnoses'])\n",
    "y = y.replace('M',0)\n",
    "y = y.replace('F',1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for LogisticRegression: Index(['on thyroxine:', 'query on thyroxine:', 'goitre:', 'tumor:', 'psych:',\n",
      "       'TSH:', 'T3 measured:', 'TT4:'],\n",
      "      dtype='object')\n",
      "Features for XGBoost: Index(['pregnant:', 'thyroid surgery:', 'lithium:', 'hypopituitary:', 'psych:',\n",
      "       'TSH measured:', 'T4U measured:', 'T4U:'],\n",
      "      dtype='object')\n",
      "Features for RandomForest: Index(['on thyroxine:', 'pregnant:', 'thyroid surgery:', 'query hyperthyroid:',\n",
      "       'lithium:', 'tumor:', 'psych:', 'FTI measured:'],\n",
      "      dtype='object')\n",
      "Features for DecisionTree: Index(['on thyroxine:', 'pregnant:', 'query hypothyroid:',\n",
      "       'query hyperthyroid:', 'lithium:', 'tumor:', 'hypopituitary:',\n",
      "       'psych:'],\n",
      "      dtype='object')\n",
      "Features for SVM: Index(['on thyroxine:', 'pregnant:', 'query hyperthyroid:', 'lithium:',\n",
      "       'tumor:', 'psych:', 'TSH measured:', 'T4U:'],\n",
      "      dtype='object')\n",
      "Features for KNN: Index(['on antithyroid medication:', 'pregnant:', 'query hypothyroid:',\n",
      "       'tumor:', 'hypopituitary:', 'psych:', 'T3 measured:', 'TBG measured:'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "models = {'LogisticRegression': LogisticRegression(),'XGBoost': XGBClassifier(),'RandomForest': RandomForestClassifier(n_estimators=100),\n",
    "    'DecisionTree': DecisionTreeClassifier(),'SVM': SVC(),'KNN': KNeighborsClassifier(n_neighbors=10, weights='distance')}\n",
    "selected_features = {}\n",
    "for name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    sfs = SequentialFeatureSelector(model, n_features_to_select=8, n_jobs=-1)\n",
    "    sfs.fit(X, y)\n",
    "    mask = sfs.get_support()\n",
    "    selected_features[name] = X.columns[mask]\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'Features for {name}: {selected_features[name]}')\n",
    "    #print(f'Time taken for {name}: {elapsed_time} seconds\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression with MinMaxScaler and SimpleImputer: 0.4655242212043855\n",
      "LogisticRegression with MinMaxScaler and KNNImputer: 0.4655242212043855\n",
      "LogisticRegression with StandardScaler and SimpleImputer: 0.4651466750182691\n",
      "LogisticRegression with StandardScaler and KNNImputer: 0.4651466750182691\n",
      "XGBoost with MinMaxScaler and SimpleImputer: 0.5516832936429743\n",
      "XGBoost with MinMaxScaler and KNNImputer: 0.5516832936429743\n",
      "XGBoost with StandardScaler and SimpleImputer: 0.5516832936429743\n",
      "XGBoost with StandardScaler and KNNImputer: 0.5516832936429743\n",
      "RandomForest with MinMaxScaler and SimpleImputer: 0.5346300159255194\n",
      "RandomForest with MinMaxScaler and KNNImputer: 0.5365891726428247\n",
      "RandomForest with StandardScaler and SimpleImputer: 0.5387100459945738\n",
      "RandomForest with StandardScaler and KNNImputer: 0.5370802378303365\n",
      "DecisionTree with MinMaxScaler and SimpleImputer: 0.4630002296025175\n",
      "DecisionTree with MinMaxScaler and KNNImputer: 0.4630002296025175\n",
      "DecisionTree with StandardScaler and SimpleImputer: 0.4630002296025175\n",
      "DecisionTree with StandardScaler and KNNImputer: 0.4630002296025175\n",
      "SVM with MinMaxScaler and SimpleImputer: 0.46448956294846705\n",
      "SVM with MinMaxScaler and KNNImputer: 0.46448956294846705\n",
      "SVM with StandardScaler and SimpleImputer: 0.46207735377255926\n",
      "SVM with StandardScaler and KNNImputer: 0.46207735377255926\n",
      "KNN with MinMaxScaler and SimpleImputer: 0.45555672945514775\n",
      "KNN with MinMaxScaler and KNNImputer: 0.45555672945514775\n",
      "KNN with StandardScaler and SimpleImputer: 0.5060268807395245\n",
      "KNN with StandardScaler and KNNImputer: 0.5060268807395245\n"
     ]
    }
   ],
   "source": [
    "selected_features = {'LogisticRegression': ['on thyroxine:', 'query on thyroxine:', 'goitre:', 'tumor:', 'psych:','TSH:', 'T3 measured:', 'TT4:'],\n",
    "    'XGBoost': ['pregnant:', 'thyroid surgery:', 'lithium:', 'hypopituitary:', 'psych:','TSH measured:', 'T4U measured:', 'T4U:'],\n",
    "    'RandomForest':['query on thyroxine:', 'pregnant:', 'lithium:', 'tumor:', 'psych:','T4U:', 'FTI measured:', 'TBG measured:'],\n",
    "    'DecisionTree': ['on thyroxine:', 'pregnant:', 'query hypothyroid:','query hyperthyroid:', 'lithium:', 'tumor:', 'hypopituitary:','psych:'],\n",
    "    'SVM':['on thyroxine:', 'pregnant:', 'query hyperthyroid:', 'lithium:','tumor:', 'psych:', 'TSH measured:', 'T4U:'],\n",
    "    'KNN': ['on antithyroid medication:', 'pregnant:', 'query hypothyroid:','tumor:', 'hypopituitary:', 'psych:', 'T3 measured:', 'TBG measured:']}\n",
    "models = [('LogisticRegression', LogisticRegression()),('XGBoost', XGBClassifier()),('RandomForest', RandomForestClassifier(n_estimators=100)),\n",
    "    ('DecisionTree', DecisionTreeClassifier()),('SVM', SVC()),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=10, weights='distance')),]\n",
    "scaling = [('MinMaxScaler', MinMaxScaler()),('StandardScaler', StandardScaler())] \n",
    "imput = [\n",
    "    ('SimpleImputer',SimpleImputer(missing_values=np.nan, strategy='median')), \n",
    "    ('KNNImputer',KNNImputer(n_neighbors=2, weights=\"uniform\"))\n",
    "    ]\n",
    "# Loop over the models\n",
    "for model_name, model in models:\n",
    "    best_features = selected_features[model_name]\n",
    "    X_best = X[best_features]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_best, y, test_size=0.2, random_state=42)\n",
    "    for scaler_name, scaler in scaling:\n",
    "        for imput_name, imputer in imput:\n",
    "            X_train_imputed = imputer.fit_transform(X_train)\n",
    "            X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "            X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "            X_test_scaled = scaler.transform(X_test_imputed)\n",
    "            \n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            print(f'{model_name} with {scaler_name} and {imput_name}:',f1_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 729 candidates, totalling 2187 fits\n",
      "Best parameters for KNN:  {'XGB__colsample_bytree': 0.5, 'XGB__gamma': 0, 'XGB__learning_rate': 0.01, 'XGB__max_depth': 3, 'XGB__min_child_weight': 1, 'XGB__subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'XGB__learning_rate': [0.01, 0.1, 0.3],\n",
    "    'XGB__max_depth': [3, 6, 9],\n",
    "    'XGB__min_child_weight': [1, 3, 5],\n",
    "    'XGB__gamma': [0, 0.1, 0.2],\n",
    "    'XGB__subsample': [0.5, 0.7, 1.0],\n",
    "    'XGB__colsample_bytree': [0.5, 0.7, 1.0]\n",
    "}\n",
    "imputer = KNNImputer()\n",
    "scaler = MinMaxScaler()\n",
    "log_r = XGBClassifier()\n",
    "grid_search = GridSearchCV(estimator=log_r, param_grid=param_grid, cv=3, n_jobs=-1, verbose=1)\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(\"Best parameters for KNN: \",  grid_search.best_params_)\n",
    "y_pred = grid_search.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Model XGBoost on Diagnoses Problem: \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "##O1\n",
    "def convert_to_target(diagnoses):\n",
    "    if diagnoses == '-':\n",
    "        return 'healthy'\n",
    "    elif diagnoses in 'ABCD':\n",
    "        return 'hyperthyroid condition'\n",
    "    elif diagnoses in 'EFGH':\n",
    "        return 'hypothyroid condition'\n",
    "    elif diagnoses in 'IJ':\n",
    "        return 'binding protein'\n",
    "    elif diagnoses in 'K':\n",
    "        return 'general health'\n",
    "    elif diagnoses in 'LMN':\n",
    "        return 'replacement therapy'\n",
    "    elif diagnoses == 'R':\n",
    "        return 'discordant results'\n",
    "    else:\n",
    "        return 'other'\n",
    "def apply_O1(data_test, data_results):\n",
    "    data_test = data_test.drop(columns=['referral source:'])\n",
    "    data_test = data_test.drop(columns=['[record identification]'])\n",
    "    drop_indices = data_test[data_test['sex:'] == '?'].index\n",
    "    data_test = data_test[data_test['sex:'] != '?']\n",
    "    columns_with_question_mark = data_test.columns[data_test.apply(lambda col: (col == '?').any())]\n",
    "    for column in columns_with_question_mark:\n",
    "        data_test[column] = data_test[column].replace('?', np.nan)\n",
    "    data_results['target'] = data_results['diagnoses'].apply(convert_to_target)\n",
    "    y = data_results['target']\n",
    "    y = y.drop(drop_indices)\n",
    "    X = data_test\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    X = X.replace('f', 0)\n",
    "    X = X.replace('t', 1)\n",
    "    X = X.replace('M', 0)\n",
    "    X = X.replace('F', 1)\n",
    "    X = X.fillna(-1)\n",
    "    best_features_xgb = ['on thyroxine:', 'pregnant:', 'thyroid surgery:', 'TSH:', 'T3:', 'TT4:','FTI:', 'TBG:']  # replace with your actual feature names\n",
    "    X_selected_xgb = X[best_features_xgb]\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(X_selected_xgb, y, test_size=0.2, random_state=42)\n",
    "    best_params_xgb = {'xgb__colsample_bytree': 0.7, 'xgb__gamma': 0.2, 'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__min_child_weight': 1, 'xgb__subsample': 0.7}\n",
    "    model = Pipeline([('imputer', KNNImputer(weights=\"distance\")),('scaler', StandardScaler()),\n",
    "    ('classifier', XGBClassifier(learning_rate=best_params_xgb['xgb__learning_rate'],max_depth=best_params_xgb['xgb__max_depth'],\n",
    "        min_child_weight=best_params_xgb['xgb__min_child_weight'],gamma=best_params_xgb['xgb__gamma'],subsample=best_params_xgb['xgb__subsample'],\n",
    "        colsample_bytree=best_params_xgb['xgb__colsample_bytree']))])\n",
    "    model.fit(X_train1, y_train1)   \n",
    "    y_pred1 = model.predict(X_test1)\n",
    "    print(\"Accuracy for Model XGBoost on Diagnoses Problem: \\n\", f1_score(y_test1, y_pred1, average='macro'))  \n",
    "apply_O1(pd.read_csv('../proj-test-data.csv'),pd.read_csv('../proj-test-class.csv'))\n",
    "\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
